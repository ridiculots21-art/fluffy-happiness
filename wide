# CONFIG
DEFAULT_LEBARAN_DATES = [
    "2023-04-22",
    "2024-04-10",
    "2025-03-31",
]

CONFIG = {
    "period_col": "periods",     # 'YYYY MM'
    "value_col": "so_nw_ct",
    "group_key": "key",
    "zone_extract_idx": 0,       # index when splitting key by '_' to get zone
    "pareto_keys": None,         # set to list/Series if restricting to pareto
    "filter_soldto": None,
    "filter_shipto": None,
}

------------------------------------------------------------------------

# Cell 2 — core helpers: lebaran -> periods, and compute per-key diffs
def to_period_str(dt: datetime) -> str:
    return dt.strftime("%Y %m")

def lebaran_to_periods(lebaran_dates):
    """Return list of dicts with lebaran_period, m1, m2, m3 for each date string YYYY-MM-DD"""
    periods = []
    for d in lebaran_dates:
        ld = datetime.strptime(d, "%Y-%m-%d")
        periods.append({
            "lebaran_date": ld,
            "lebaran_period": to_period_str(ld),
            "m1": to_period_str(ld - relativedelta(months=1)),
            "m2": to_period_str(ld - relativedelta(months=2)),
            "m3": to_period_str(ld - relativedelta(months=3)),
        })
    return periods

def compute_lebaran_diffs_for_one(so_df: pl.DataFrame, lebaran_info: dict, cfg: dict = CONFIG) -> pl.DataFrame:
    """
    For a single lebaran event, build wide table per key with columns:
      key, zone, m3, m2, m1, lebaran, diff_m1_lebaran, diff_m3_lebaran, diff_m2_m1, diff_m3_m2
    Missing months are filled with 0 (configurable approach).
    """
    period_col = cfg["period_col"]
    val_col = cfg["value_col"]
    key_col = cfg["group_key"]

    required = [lebaran_info["m3"], lebaran_info["m2"], lebaran_info["m1"], lebaran_info["lebaran_period"]]

    tmp = (
        so_df
        .filter(pl.col(period_col).is_in(required))
        .select([pl.col(key_col), pl.col(period_col), pl.col(val_col)])
        .group_by([key_col, period_col])
        .agg(pl.col(val_col).sum().alias(val_col))
    )

    pivoted = tmp.pivot(
        on=period_col,
        index=key_col,
        values=val_col,
        aggregate_function="sum",
        sort_columns=True
    ).fill_null(0)

    # Ensure columns exist even if absent
    for p in required:
        if p not in pivoted.columns:
            pivoted = pivoted.with_columns(pl.lit(0).alias(p))

    pivoted = pivoted.with_columns(
        pl.col(required[0]).alias("m3"),
        pl.col(required[1]).alias("m2"),
        pl.col(required[2]).alias("m1"),
        pl.col(required[3]).alias("lebaran"),
    )

    # extract zone from key (flexible index)
    pivoted = pivoted.with_columns(
        zone = pl.col(key_col).str.split("_").list.get(cfg["zone_extract_idx"])
    )

    pivoted = pivoted.with_columns(
        (pl.col("m1") - pl.col("lebaran")).alias("diff_m1_lebaran"),
        (pl.col("m3") - pl.col("lebaran")).alias("diff_m3_lebaran"),
        (pl.col("m2") - pl.col("m1")).alias("diff_m2_m1"),
        (pl.col("m3") - pl.col("m2")).alias("diff_m3_m2"),
    )

    out = pivoted.select([
        key_col, "zone", "m3", "m2", "m1", "lebaran",
        "diff_m1_lebaran","diff_m3_lebaran","diff_m2_m1","diff_m3_m2"
    ])

    return out

def compute_lebaran_diffs(so_df: pl.DataFrame, lebaran_dates, cfg: dict = CONFIG):
    """
    Runs compute_lebaran_diffs_for_one for each lebaran date.
    Returns:
      - per_event_concat (Polars DF) : per-key per-event diffs (adds column lebaran_period)
      - national_summary_unweighted (Pandas DF) : simple means (unweighted)
      - zone_summary_unweighted (Pandas DF) : simple means per zone (unweighted)
    """
    infos = lebaran_to_periods(lebaran_dates)
    per_event_dfs = []
    national_rows = []
    zone_rows = []

    df = so_df
    if cfg.get("pareto_keys") is not None:
        df = df.filter(pl.col(cfg["group_key"]).is_in(cfg["pareto_keys"]))
    if cfg.get("filter_soldto") is not None:
        df = df.filter(pl.col("key").str.contains(str(cfg["filter_soldto"])))
    if cfg.get("filter_shipto") is not None:
        df = df.filter(pl.col("key").str.contains(str(cfg["filter_shipto"])))

    for info in infos:
        diffs = compute_lebaran_diffs_for_one(df, info, cfg)
        diffs = diffs.with_columns(pl.lit(info["lebaran_period"]).alias("lebaran_period"))
        per_event_dfs.append(diffs)

        nat = diffs.select([
            pl.mean("diff_m1_lebaran").alias("avg_diff_m1_lebaran"),
            pl.mean("diff_m3_lebaran").alias("avg_diff_m3_lebaran"),
            pl.mean("diff_m2_m1").alias("avg_diff_m2_m1"),
            pl.mean("diff_m3_m2").alias("avg_diff_m3_m2")
        ]).with_columns(pl.lit(info["lebaran_period"]).alias("lebaran_period"))
        national_rows.append(nat.to_pandas())

        zone_avg = diffs.group_by("zone").agg([
            pl.mean("diff_m1_lebaran").alias("avg_diff_m1_lebaran"),
            pl.mean("diff_m3_lebaran").alias("avg_diff_m3_lebaran"),
            pl.mean("diff_m2_m1").alias("avg_diff_m2_m1"),
            pl.mean("diff_m3_m2").alias("avg_diff_m3_m2"),
        ]).with_columns(pl.lit(info["lebaran_period"]).alias("lebaran_period"))
        zone_rows.append(zone_avg.to_pandas())

    per_event_concat = pl.concat(per_event_dfs)
    national_summary = pd.concat(national_rows, ignore_index=True)
    zone_summary = pd.concat(zone_rows, ignore_index=True)

    return per_event_concat, national_summary, zone_summary

------------------------------------------------------------------------

# Cell 3 — weighted summaries + example usage

def build_weight_map(so_df: pl.DataFrame, year_str="2025", period_col="periods", key_col="key", val_col="so_nw_ct"):
    """
    Build weight mapping per key using total sales in the year_str (e.g., '2025').
    Returns a Polars DataFrame with columns ['key','sales_{year}'].
    """
    sel = so_df.filter(pl.col(period_col).str.contains(year_str))
    weight_map = sel.group_by(key_col).agg(pl.col(val_col).sum().alias(f"sales_{year_str}"))
    return weight_map

def weighted_summaries(per_event_df: pl.DataFrame, weight_map: pl.DataFrame, weight_col_name: str, 
                       lebaran_period_col="lebaran_period"):
    """
    per_event_df: Polars DF from compute_lebaran_diffs (must include key, zone, diffs, lebaran_period)
    weight_map: Polars DF with ['key', weight_col_name]
    Returns:
      - national_weighted_df (Pandas): weighted averages per lebaran_period
      - zone_weighted_df (Pandas): weighted averages per lebaran_period per zone
    """
    merged = per_event_df.join(weight_map, on="key", how="left").fill_null(0)
    wcol = weight_col_name

    # national numerators/denominators per lebaran_period
    nat = (
        merged
        .group_by(lebaran_period_col)
        .agg([
            (pl.col("diff_m1_lebaran") * pl.col(wcol)).sum().alias("num_m1"),
            (pl.col("diff_m3_lebaran") * pl.col(wcol)).sum().alias("num_m3"),
            (pl.col("diff_m2_m1") * pl.col(wcol)).sum().alias("num_m2_m1"),
            (pl.col("diff_m3_m2") * pl.col(wcol)).sum().alias("num_m3_m2"),
            pl.col(wcol).sum().alias("den")
        ])
        .with_columns([
            pl.when(pl.col("den") == 0).then(None).otherwise(pl.col("num_m1") / pl.col("den")).alias("w_avg_diff_m1_lebaran"),
            pl.when(pl.col("den") == 0).then(None).otherwise(pl.col("num_m3") / pl.col("den")).alias("w_avg_diff_m3_lebaran"),
            pl.when(pl.col("den") == 0).then(None).otherwise(pl.col("num_m2_m1") / pl.col("den")).alias("w_avg_diff_m2_m1"),
            pl.when(pl.col("den") == 0).then(None).otherwise(pl.col("num_m3_m2") / pl.col("den")).alias("w_avg_diff_m3_m2"),
        ])
    )

    # zone-level weighted averages
    zone = (
        merged
        .group_by(["lebaran_period", "zone"])
        .agg([
            (pl.col("diff_m1_lebaran") * pl.col(wcol)).sum().alias("num_m1"),
            (pl.col("diff_m3_lebaran") * pl.col(wcol)).sum().alias("num_m3"),
            (pl.col("diff_m2_m1") * pl.col(wcol)).sum().alias("num_m2_m1"),
            (pl.col("diff_m3_m2") * pl.col(wcol)).sum().alias("num_m3_m2"),
            pl.col(wcol).sum().alias("den")
        ])
        .with_columns([
            pl.when(pl.col("den") == 0).then(None).otherwise(pl.col("num_m1") / pl.col("den")).alias("w_avg_diff_m1_lebaran"),
            pl.when(pl.col("den") == 0).then(None).otherwise(pl.col("num_m3") / pl.col("den")).alias("w_avg_diff_m3_lebaran"),
            pl.when(pl.col("den") == 0).then(None).otherwise(pl.col("num_m2_m1") / pl.col("den")).alias("w_avg_diff_m2_m1"),
            pl.when(pl.col("den") == 0).then(None).otherwise(pl.col("num_m3_m2") / pl.col("den")).alias("w_avg_diff_m3_m2"),
        ])
    )

    return nat.to_pandas(), zone.to_pandas()

# ---------- Example usage (run after previous cells) ----------
# 1) compute per-event diffs (unweighted)
# per_event, national_unweighted, zone_unweighted = compute_lebaran_diffs(so_fcst_df, DEFAULT_LEBARAN_DATES, CONFIG)

# 2) build weight map (2025 sales per key)
# weight_map = build_weight_map(so_fcst_df, year_str="2025", period_col=CONFIG["period_col"], key_col=CONFIG["group_key"], val_col=CONFIG["value_col"])

# 3) call weighted summaries
# national_weighted, zone_weighted = weighted_summaries(per_event, weight_map, weight_col_name="sales_2025")

# 4) save or inspect
# national_weighted.to_csv("national_weighted_lebaran_summary.csv", index=False)
# zone_weighted.to_csv("zone_weighted_lebaran_summary.csv", index=False)

# 5) quick plot example (national weighted)
# display(national_weighted)
# melted = pd.melt(national_weighted, id_vars=["lebaran_period"], value_vars=[
#     "w_avg_diff_m1_lebaran","w_avg_diff_m3_lebaran","w_avg_diff_m2_m1","w_avg_diff_m3_m2"
# ], var_name="metric", value_name="value")
# plt.figure(figsize=(10,4))
# sns.barplot(data=melted, x="lebaran_period", y="value", hue="metric")
# plt.axhline(0, color="k", linewidth=0.6)
# plt.title("Weighted national diffs (weights = 2025 sales per key)")
# plt.show()

------------------------------------------------------------------------

# ===== Single Cell: Monthly Sales Plot with Lebaran (April) Markers =====

import polars as pl
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# ---------------------------
# 1. PREPARE DATA
# ---------------------------
# Assumes: so_fcst_df exists
# Required columns:
# - "periods" (format: "YYYY MM")
# - "so_nw_ct" (sales value)
# - "key" (format assumed: something_soldto_shipto or similar, separated by "_")

df = so_fcst_df

# --- Extract soldto and shipto from key ---
# Adjust index positions below if needed
# Example: if key = "material_soldto_shipto"
# then soldto_index = 1, shipto_index = 2

soldto_index = 1
shipto_index = 2

df = df.with_columns([
    pl.col("key").str.split("_").list.get(soldto_index).alias("soldto"),
    pl.col("key").str.split("_").list.get(shipto_index).alias("shipto")
])

# ---------------------------
# 2. MANUAL FILTER (EDIT HERE IF NEEDED)
# ---------------------------

# OPTION A: No filter → comment both lines below
# df = df.filter(pl.col("soldto") == "YOUR_SOLDTO_CODE")
# df = df.filter(pl.col("shipto") == "YOUR_SHIPTO_CODE")

# OPTION B: Multiple values
# df = df.filter(pl.col("soldto").is_in(["A123", "B456"]))

# ---------------------------
# 3. AGGREGATE MONTHLY SALES
# ---------------------------

monthly = (
    df.group_by("periods")
      .agg(pl.col("so_nw_ct").sum().alias("monthly_sales"))
      .sort("periods")
)

monthly_pd = monthly.to_pandas()
monthly_pd["period_dt"] = pd.to_datetime(monthly_pd["periods"], format="%Y %m")

# Restrict to 2023–2025
monthly_pd = monthly_pd[
    (monthly_pd["period_dt"] >= "2023-01-01") &
    (monthly_pd["period_dt"] <= "2025-12-31")
].copy()

monthly_pd = monthly_pd.sort_values("period_dt")

# ---------------------------
# 4. PLOT
# ---------------------------

plt.figure(figsize=(14,5))
sns.lineplot(data=monthly_pd, x="period_dt", y="monthly_sales", marker="o")

plt.title("Monthly Sales (2023–2025) with Lebaran = April")
plt.xlabel("Period")
plt.ylabel("Total Sales (so_nw_ct)")

# Lebaran assumed April (month=4)
for year in [2023, 2024, 2025]:
    lebaran_date = pd.Timestamp(f"{year}-04-01")
    plt.axvline(lebaran_date, linestyle="--")
    plt.text(
        lebaran_date,
        monthly_pd["monthly_sales"].max() * 1.02,
        f"Lebaran {year}",
        ha="center",
        va="bottom",
        fontsize=9
    )

plt.tight_layout()
plt.show()


------------------------------------------------------------------------

# ===== Task 2: Compare 1 Month Before (March) vs During Lebaran (April) =====

import polars as pl
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Assumes so_fcst_df exists with:
# - periods (format: "YYYY MM")
# - so_nw_ct
# - key

df = so_fcst_df

# ---------------------------
# 1. Prepare datetime
# ---------------------------
df = df.with_columns(
    pl.col("periods").str.strptime(pl.Date, format="%Y %m").alias("period_dt")
)

df = df.with_columns([
    pl.col("period_dt").dt.year().alias("year"),
    pl.col("period_dt").dt.month().alias("month")
])

# Restrict to 2023–2025
df = df.filter(pl.col("year").is_in([2023, 2024, 2025]))

# ---------------------------
# 2. OPTIONAL: Pareto Filter
# ---------------------------
# If you want Pareto filtering:
# Set PARETO_RATIO to something like 0.8 (top 80% contributors)
# If not needed, set to None

PARETO_RATIO = None   # Example: 0.8

if PARETO_RATIO is not None:
    total_by_key = (
        df.group_by("key")
          .agg(pl.col("so_nw_ct").sum().alias("total_sales"))
          .sort("total_sales", descending=True)
    )

    total_sum = total_by_key["total_sales"].sum()

    total_by_key = total_by_key.with_columns(
        (pl.col("total_sales").cumsum() / total_sum).alias("cum_ratio")
    )

    top_keys = total_by_key.filter(pl.col("cum_ratio") <= PARETO_RATIO)["key"]

    df = df.filter(pl.col("key").is_in(top_keys))

# ---------------------------
# 3. Get March (t-1) and April (Lebaran)
# ---------------------------

lebaran_month = 4
before_month = 3

comparison = (
    df.filter(pl.col("month").is_in([before_month, lebaran_month]))
      .group_by(["key", "year", "month"])
      .agg(pl.col("so_nw_ct").sum().alias("sales"))
)

comparison_pd = comparison.to_pandas()

# Pivot so we get columns: March and April
pivot = comparison_pd.pivot_table(
    index=["key", "year"],
    columns="month",
    values="sales",
    fill_value=0
).reset_index()

pivot.columns.name = None
pivot = pivot.rename(columns={
    before_month: "before_sales",
    lebaran_month: "lebaran_sales"
})

# Calculate difference
pivot["difference"] = pivot["lebaran_sales"] - pivot["before_sales"]
pivot["pct_change"] = (
    pivot["difference"] / pivot["before_sales"].replace(0, pd.NA)
)

print("Sample comparison:")
display(pivot.head())

# ---------------------------
# 4. Aggregate Overall Impact
# ---------------------------

summary = pivot.groupby("year")[["before_sales", "lebaran_sales"]].sum().reset_index()

print("Year-level summary:")
display(summary)

# ---------------------------
# 5. Plot Before vs During
# ---------------------------

plt.figure(figsize=(10,5))
sns.lineplot(data=summary, x="year", y="before_sales", marker="o", label="March (t-1)")
sns.lineplot(data=summary, x="year", y="lebaran_sales", marker="o", label="April (Lebaran)")

plt.title("Total Sales: 1 Month Before vs During Lebaran")
plt.ylabel("Total Sales (so_nw_ct)")
plt.xlabel("Year")
plt.tight_layout()
plt.show()



comparison = (
    df.filter(pl.col("month").is_in([3, 4]))
      .group_by(["year", "month"])
      .agg(pl.col("so_nw_ct").sum().alias("sales"))
)

comparison_pd = comparison.to_pandas()

pivot = comparison_pd.pivot(
    index="year",
    columns="month",
    values="sales"
).reset_index()

pivot = pivot.rename(columns={
    3: "March",
    4: "April"
})

pivot = pivot.fillna(0)

print("Year-level totals:")
display(pivot)

# -------------------------------------------------
# 6. Grouped Bar Chart
# -------------------------------------------------

x = np.arange(len(pivot["year"]))
width = 0.35

plt.figure(figsize=(10,5))

plt.bar(x - width/2, pivot["March"], width, label="March (t-1)")
plt.bar(x + width/2, pivot["April"], width, label="April (Lebaran)")

plt.xticks(x, pivot["year"])
plt.ylabel("Total Sales (so_nw_ct)")
plt.title("Sales Comparison: March vs April (Lebaran)")
plt.legend()

plt.tight_layout()
plt.show()


------------------------------------------------------------------------



------------------------------------------------------------------------



------------------------------------------------------------------------
