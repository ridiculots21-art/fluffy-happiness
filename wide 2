def prepare_df_and_pareto(so_fcst_df: pl.DataFrame, pareto_ratio: float = None):
    
    # Convert periods to date
    df = so_fcst_df.with_columns(
        pl.col("periods").str.strptime(pl.Date, "%Y %m").alias("period_dt")
    ).with_columns([
        pl.col("period_dt").dt.year().alias("year"),
        pl.col("period_dt").dt.month().alias("month")
    ])
    
    # Keep only 2023–2025
    df = df.filter(pl.col("year").is_in([2023, 2024, 2025]))

    # ----------------------
    # Pareto function
    # ----------------------
    def apply_pareto(df_input: pl.DataFrame, ratio: float):

        total_by_key = (
            df_input
            .group_by("key")
            .agg(pl.col("so_nw_ct").sum().alias("total_sales"))
            .sort("total_sales", descending=True)
        )

        total_sum = total_by_key["total_sales"].sum()

        total_by_key = total_by_key.with_columns(
            (pl.col("total_sales").cumsum() / total_sum).alias("cum_ratio")
        )

        top_keys = total_by_key.filter(
            pl.col("cum_ratio") <= ratio
        )["key"]

        return df_input.filter(pl.col("key").is_in(top_keys))

    # Apply pareto if requested
    if pareto_ratio is not None:
        df_pareto = apply_pareto(df, pareto_ratio)
    else:
        df_pareto = df

    return df, df_pareto


-----------------------------------------------------------------------

pareto_ratio = 0.8   # or None if you want all

df, df_pareto = prepare_df_and_pareto(so_fcst_df, pareto_ratio)

print(df_pareto.shape)
df_pareto.head()

-----------------------------------------------------------------------

# ============================================
# CELL 2 — BUILD LEBARAN STRUCTURE
# ============================================

# Flexible Lebaran configuration
lebaran_cfg = {
    2023: 4,   # April
    2024: 4,   # April
    2025: 3    # March
}

all_years_list = []

for year, leb_month in lebaran_cfg.items():
    
    # Define dates
    lebaran_dt = datetime(year, leb_month, 1)
    
    p_leb = lebaran_dt.strftime("%Y %m")
    p_m1  = (lebaran_dt - relativedelta(months=1)).strftime("%Y %m")
    p_m2  = (lebaran_dt - relativedelta(months=2)).strftime("%Y %m")
    p_m3  = (lebaran_dt - relativedelta(months=3)).strftime("%Y %m")
    
    print(f"\nProcessing Lebaran {year}")
    print("Lebaran:", p_leb)
    print("M-1:", p_m1)
    print("M-2:", p_m2)
    print("M-3:", p_m3)
    
    # Filter only required periods
    temp_df = df_pareto.filter(
        pl.col("periods").is_in([p_leb, p_m1, p_m2, p_m3])
    )
    
    # Pivot
    pivot_df = temp_df.pivot(
        on="periods",
        index="key",
        values="so_nw_ct",
        aggregate_function="sum"
    )
    
    # Ensure all columns exist
    for colname in [p_leb, p_m1, p_m2, p_m3]:
        if colname not in pivot_df.columns:
            pivot_df = pivot_df.with_columns(pl.lit(0).alias(colname))
    
    # Rename to standard names
    pivot_df = pivot_df.rename({
        p_leb: "lebaran_sales",
        p_m1: "m1_sales",
        p_m2: "m2_sales",
        p_m3: "m3_sales"
    })
    
    # Add year column
    pivot_df = pivot_df.with_columns(
        pl.lit(year).alias("lebaran_year")
    )
    
    all_years_list.append(pivot_df)

# Combine all years
lebaran_base_df = pl.concat(all_years_list)

print("\nBase Lebaran Data Shape:")
print(lebaran_base_df.shape)

lebaran_base_df.head()

-----------------------------------------------------------------------

# ============================================
# CELL 3 — CALCULATE DIFF + PERCENTAGE
# ============================================

lebaran_metrics_df = lebaran_base_df.with_columns([

    # -----------------------
    # Raw Differences
    # -----------------------
    (pl.col("m3_sales") - pl.col("lebaran_sales")).alias("d_3m_minus_leb"),
    (pl.col("m1_sales") - pl.col("lebaran_sales")).alias("d_1m_minus_leb"),
    (pl.col("m2_sales") - pl.col("m1_sales")).alias("d_2m_minus_1m"),
    (pl.col("m3_sales") - pl.col("m2_sales")).alias("d_3m_minus_2m"),

]).with_columns([

    # -----------------------
    # Percentage Ratios (A - B) / A
    # -----------------------
    pl.when(pl.col("m3_sales") > 0)
      .then((pl.col("m3_sales") - pl.col("lebaran_sales")) / pl.col("m3_sales"))
      .otherwise(0)
      .alias("pct_3m_minus_leb"),

    pl.when(pl.col("m1_sales") > 0)
      .then((pl.col("m1_sales") - pl.col("lebaran_sales")) / pl.col("m1_sales"))
      .otherwise(0)
      .alias("pct_1m_minus_leb"),

    pl.when(pl.col("m2_sales") > 0)
      .then((pl.col("m2_sales") - pl.col("m1_sales")) / pl.col("m2_sales"))
      .otherwise(0)
      .alias("pct_2m_minus_1m"),

    pl.when(pl.col("m3_sales") > 0)
      .then((pl.col("m3_sales") - pl.col("m2_sales")) / pl.col("m3_sales"))
      .otherwise(0)
      .alias("pct_3m_minus_2m"),

]).with_columns([

    # -----------------------
    # Average of the 4 percentages
    # -----------------------
    (
        pl.col("pct_3m_minus_leb") +
        pl.col("pct_1m_minus_leb") +
        pl.col("pct_2m_minus_1m") +
        pl.col("pct_3m_minus_2m")
    ) / 4
    .alias("avg_pct_change")

])

print("Lebaran Metrics Shape:")
print(lebaran_metrics_df.shape)

lebaran_metrics_df.head()

-----------------------------------------------------------------------

# ============================================
# CELL 4 — NATIONAL NUMBERS
# ============================================

# Simple mean across all keys
national_simple_df = (
    lebaran_metrics_df
    .group_by("lebaran_year")
    .agg([
        pl.col("avg_pct_change").mean().alias("national_avg_pct"),
        pl.count().alias("number_of_keys"),
        pl.col("lebaran_sales").sum().alias("total_lebaran_sales")
    ])
)

# Weighted mean (weight by lebaran_sales)
national_weighted_df = (
    lebaran_metrics_df
    .with_columns(
        (pl.col("avg_pct_change") * pl.col("lebaran_sales")).alias("weighted_component")
    )
    .group_by("lebaran_year")
    .agg([
        pl.col("weighted_component").sum().alias("weighted_sum"),
        pl.col("lebaran_sales").sum().alias("total_lebaran_sales")
    ])
    .with_columns(
        (pl.col("weighted_sum") / pl.col("total_lebaran_sales")).alias("national_weighted_avg_pct")
    )
    .select([
        "lebaran_year",
        "national_weighted_avg_pct"
    ])
)

# Combine
national_summary_df = national_simple_df.join(
    national_weighted_df,
    on="lebaran_year",
    how="left"
)

national_summary_df.sort("lebaran_year")

# ============================================
# CELL 4 — NATIONAL 4 METRICS + ALL YEARS
# ============================================

# ---- Per Year ----
national_by_year_df = (
    lebaran_metrics_df
    .group_by("lebaran_year")
    .agg([
        pl.col("pct 3m - leb").mean().alias("national pct 3m - leb"),
        pl.col("pct 1m - leb").mean().alias("national pct 1m - leb"),
        pl.col("pct 2m - 1m").mean().alias("national pct 2m - 1m"),
        pl.col("pct 3m - 2m").mean().alias("national pct 3m - 2m")
    ])
    .sort("lebaran_year")
)

# ---- All Years Combined ----
national_all_years_df = (
    lebaran_metrics_df
    .select([
        pl.lit("All Years").alias("lebaran_year"),
        pl.col("pct 3m - leb").mean().alias("national pct 3m - leb"),
        pl.col("pct 1m - leb").mean().alias("national pct 1m - leb"),
        pl.col("pct 2m - 1m").mean().alias("national pct 2m - 1m"),
        pl.col("pct 3m - 2m").mean().alias("national pct 3m - 2m")
    ])
)

# ---- Combine ----
national_summary_df = pl.concat([
    national_by_year_df,
    national_all_years_df
])

national_summary_df

-----------------------------------------------------------------------

# ============================================
# CELL 5 — ZONE LEVEL METRICS
# ============================================

# ---- Per Year per Zone ----
zone_by_year_df = (
    lebaran_metrics_df
    .group_by(["lebaran_year", "zone"])
    .agg([
        pl.col("pct 3m - leb").mean().alias("zone pct 3m - leb"),
        pl.col("pct 1m - leb").mean().alias("zone pct 1m - leb"),
        pl.col("pct 2m - 1m").mean().alias("zone pct 2m - 1m"),
        pl.col("pct 3m - 2m").mean().alias("zone pct 3m - 2m")
    ])
    .sort(["lebaran_year", "zone"])
)

# ---- All Years per Zone ----
zone_all_years_df = (
    lebaran_metrics_df
    .group_by("zone")
    .agg([
        pl.col("pct 3m - leb").mean().alias("zone pct 3m - leb"),
        pl.col("pct 1m - leb").mean().alias("zone pct 1m - leb"),
        pl.col("pct 2m - 1m").mean().alias("zone pct 2m - 1m"),
        pl.col("pct 3m - 2m").mean().alias("zone pct 3m - 2m")
    ])
    .with_columns(
        pl.lit("All Years").alias("lebaran_year")
    )
    .select([
        "lebaran_year",
        "zone",
        "zone pct 3m - leb",
        "zone pct 1m - leb",
        "zone pct 2m - 1m",
        "zone pct 3m - 2m"
    ])
)

# ---- Combine ----
zone_summary_df = pl.concat([
    zone_by_year_df,
    zone_all_years_df
])

zone_summary_df

-----------------------------------------------------------------------

# ============================================
# FIX — Add Zone Back to lebaran_metrics_df
# ============================================

key_zone_map = (
    df_pareto
    .select(["key", "zone"])
    .unique()
)

lebaran_metrics_df = (
    lebaran_metrics_df
    .join(key_zone_map, on="key", how="left")
)

lebaran_metrics_df.columns

-----------------------------------------------------------------------
lebaran_metrics_df.select([
    pl.col("pct 3m - leb").describe(),
    pl.col("pct 1m - leb").describe(),
    pl.col("pct 2m - 1m").describe(),
    pl.col("pct 3m - 2m").describe(),
])


import matplotlib.pyplot as plt

# Convert to pandas for plotting
plot_df = lebaran_metrics_df.to_pandas()

plt.figure()
plt.hist(plot_df["pct 3m - leb"], bins=50)
plt.title("Distribution of pct 3m - leb (Raw)")
plt.xlabel("pct 3m - leb")
plt.ylabel("Frequency")
plt.show()

lebaran_metrics_df.select([
    pl.col("pct 3m - leb").min(),
    pl.col("pct 3m - leb").max(),
    pl.col("pct 3m - leb").mean(),
])
-----------------------------------------------------------------------

# ============================================
# STABILITY FILTER — REMOVE SMALL DENOMINATORS
# ============================================

min_threshold = 10

lebaran_metrics_stable_df = lebaran_metrics_df.filter(
    (pl.col("m3_sales") > min_threshold) &
    (pl.col("m2_sales") > min_threshold) &
    (pl.col("m1_sales") > min_threshold)
)

print("Before filter:", lebaran_metrics_df.shape)
print("After filter :", lebaran_metrics_stable_df.shape)


lebaran_metrics_stable_df.select([
    pl.col("pct 3m - leb").min().alias("min"),
    pl.col("pct 3m - leb").max().alias("max"),
    pl.col("pct 3m - leb").mean().alias("mean"),
])


import matplotlib.pyplot as plt

plot_df = lebaran_metrics_stable_df.to_pandas()

plt.figure()
plt.hist(plot_df["pct 3m - leb"], bins=50)
plt.title("Distribution of pct 3m - leb (Stable Only)")
plt.show()

-----------------------------------------------------------------------

lebaran_metrics_df.sort("pct 3m - leb").select([
    "key",
    "lebaran_year",
    "m3_sales",
    "lebaran_sales",
    "pct 3m - leb"
]).head(10)

lebaran_metrics_df.select(
    (pl.col("lebaran_sales") / pl.col("m3_sales")).max().alias("max_leb_over_m3")
)

lebaran_base_df.select([
    pl.col("m3_sales").is_null().sum().alias("m3_null_count"),
    (pl.col("m3_sales") == 0).sum().alias("m3_zero_count"),
])

-----------------------------------------------------------------------

lebaran_plot_df = lebaran_metrics_df.filter(
    pl.all_horizontal([
        pl.col("pct 3m - leb").is_finite(),
        pl.col("pct 1m - leb").is_finite(),
        pl.col("pct 2m - 1m").is_finite(),
        pl.col("pct 3m - 2m").is_finite(),
    ])
)

-----

yearly_ratio_df = (
    lebaran_plot_df
    .group_by("year")
    .agg([
        pl.col("pct 3m - leb").mean().alias("mean_3m_leb"),
        pl.col("pct 1m - leb").mean().alias("mean_1m_leb"),
        pl.col("pct 2m - 1m").mean().alias("mean_2m_1m"),
        pl.col("pct 3m - 2m").mean().alias("mean_3m_2m"),
    ])
    .sort("year")
)

yearly_ratio_df

----

yearly_pd = yearly_ratio_df.to_pandas()

----

plt.figure()
plt.plot(yearly_pd["year"], yearly_pd["mean_3m_leb"])
plt.title("Mean pct 3M - Lebaran by Year")
plt.xlabel("Year")
plt.ylabel("Mean Ratio")
plt.show()

plt.figure()
plt.plot(yearly_pd["year"], yearly_pd["mean_1m_leb"])
plt.title("Mean pct 1M - Lebaran by Year")
plt.xlabel("Year")
plt.ylabel("Mean Ratio")
plt.show()

plt.figure()
plt.plot(yearly_pd["year"], yearly_pd["mean_2m_1m"])
plt.title("Mean pct 2M - 1M by Year")
plt.xlabel("Year")
plt.ylabel("Mean Ratio")
plt.show()

plt.figure()
plt.plot(yearly_pd["year"], yearly_pd["mean_3m_2m"])
plt.title("Mean pct 3M - 2M by Year")
plt.xlabel("Year")
plt.ylabel("Mean Ratio")
plt.show()
-----------------------------------------------------------------------
year_check = 2023

year_df = lebaran_metrics_df.filter(
    pl.col("lebaran_year") == year_check
)

year_df.shape

---
year_df.sort("pct 3m - leb", descending=True).head(10) # most positive

year_df.sort("pct 3m - leb").head(10) # most negative


-----------------------------------------------------------------------

year_check = 2023

year_df = (
    lebaran_metrics_df
    .filter(pl.col("lebaran_year") == year_check)
    .filter(pl.col("pct 3m - leb").is_finite())
)

pd_df = year_df.to_pandas()

plt.figure()
plt.scatter(pd_df["m3_sales"], pd_df["pct 3m - leb"])
plt.xlabel("M3 Sales (Denominator)")
plt.ylabel("Pct 3M - Leb")
plt.title("Ratio vs Denominator (2023)")
plt.show()


plt.figure()
plt.hist(pd_df["pct 3m - leb"].clip(-10, 10), bins=100)
plt.title("Clipped Ratio Distribution (2023)")
plt.show()

-----------------------------------------------------------------------

lebaran_metric_stable_df = (
    lebaran_metrics_df
    .filter(
        (pl.col("m3_sales") > 0) &
        (pl.col("m2_sales") > 0) &
        (pl.col("m1_sales") > 0)
    )
)


lebaran_metric_stable_df.select([
    (pl.col("m3_sales") == 0).sum().alias("m3_zero"),
    (pl.col("m2_sales") == 0).sum().alias("m2_zero"),
    (pl.col("m1_sales") == 0).sum().alias("m1_zero"),
])


lebaran_metric_stable_df.select([
    pl.col("pct 3m - leb").min().alias("min_3m_leb"),
    pl.col("pct 3m - leb").max().alias("max_3m_leb"),
    pl.col("pct 1m - leb").min().alias("min_1m_leb"),
    pl.col("pct 1m - leb").max().alias("max_1m_leb"),
])
-----------------------------------------------------------------------

year_check = 2023

year_df = lebaran_metric_stable_df.filter(
    pl.col("lebaran_year") == year_check
)

----------

extreme_neg = (
    year_df
    .sort("pct 3m - leb")
    .head(1)
)

-----------

extreme_pos = (
    year_df
    .sort("pct 3m - leb", descending=True)
    .head(1)
)

---------

neg_key = extreme_neg.select("key_combination").item()
pos_key = extreme_pos.select("key_combination").item()

---------

neg_sales = year_df.filter(pl.col("key_combination") == neg_key)
pos_sales = year_df.filter(pl.col("key_combination") == pos_key)

----------

neg_pd = neg_sales.to_pandas()
pos_pd = pos_sales.to_pandas()

----------

import matplotlib.pyplot as plt

plt.figure()
plt.plot(
    ["M3", "M2", "M1", "Leb"],
    [
        neg_pd["m3_sales"].values[0],
        neg_pd["m2_sales"].values[0],
        neg_pd["m1_sales"].values[0],
        neg_pd["lebaran_sales"].values[0],
    ]
)
plt.title(f"Extreme Negative Case - {year_check}")
plt.ylabel("Sales")
plt.show()

----------

plt.figure()
plt.plot(
    ["M3", "M2", "M1", "Leb"],
    [
        pos_pd["m3_sales"].values[0],
        pos_pd["m2_sales"].values[0],
        pos_pd["m1_sales"].values[0],
        pos_pd["lebaran_sales"].values[0],
    ]
)
plt.title(f"Extreme Positive Case - {year_check}")
plt.ylabel("Sales")
plt.show()
-----------------------------------------------------------------------

# CELL A — pareto subset and monthly average (per-month mean across pareto keys)
import polars as pl
import pandas as pd

pareto_ratio = 0.8  # your chosen pareto

# 1) get df_pareto (reuse your prepare_df_and_pareto function)
_, df_pareto = prepare_df_and_pareto(so_fcst_df, pareto_ratio)

# 2) make sure periods -> proper date (first-of-month)
df_pareto = df_pareto.with_columns(
    pl.col("periods").str.strptime(pl.Date, "%Y %m").alias("period_dt")
)

# 3) drop null/invalid so_nw_ct if any (safety)
df_pareto = df_pareto.filter(pl.col("so_nw_ct").is_finite())

# 4) compute average monthly sales across all pareto keys
monthly_avg = (
    df_pareto
    .group_by("period_dt")
    .agg(
        pl.col("so_nw_ct").mean().alias("monthly_avg")   # average across keys for that month
    )
    .sort("period_dt")
)

# 5) convert to pandas for plotting convenience
monthly_pd = monthly_avg.to_pandas()
monthly_pd["period_dt"] = pd.to_datetime(monthly_pd["period_dt"])  # ensure pandas datetime dtype

# quick peek
monthly_pd.head()

----------

# CELL B — plot average monthly series and mark Lebaran dates
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd

# ensure monthly_pd exists from previous cell
# generate all months between min and max
all_months = pd.date_range(
  start=monthly_pd["period_dt"].min(),
  end=monthly_pd["period_dt"].max(),
  freq="MS"  # Month Start frequency
)

plt.figure(figsize=(20,5))
sns.lineplot(data=monthly_pd, x="period_dt", y="monthly_avg", marker="o")
plt.title("Average Monthly Sales (Pareto 80 keys)")
plt.xlabel("Period")
plt.ylabel("Average Sales (so_nw_ct)")

# Force all months on x-axis
plt.xticks(all_months, rotation=45)

# Lebaran markers — use your lebaran mapping:
lebaran_cfg = {2023:4, 2024:4, 2025:3}
for year, month in lebaran_cfg.items():
    lebaran_date = pd.Timestamp(f"{year}-{month:02d}-01")
    plt.axvline(lebaran_date, linestyle="--", linewidth=1.0)
    plt.text(
      lebaran_date,
      monthly_pd["monthly_avg"].max() * 1.02,
      f"Lebaran {year}",
      ha="center",
      va="bottom",
      fontsize=9
    )

plt.tight_layout()
plt.show()

-------

# CELL C — top-10 keys by pct 3m - leb then per-key monthly avg (one line per key)
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd

# get top 10 keys (make sure column name matches your alias)
top10_keys = lebaran_metrics_df.sort("pct 3m - leb").head(10)["key"].to_list()

# filter df_pareto for those keys and compute monthly average per key
df_top_keys = df_pareto.filter(pl.col("key").is_in(top10_keys))

per_key_monthly = (
    df_top_keys
    .group_by(["key", "period_dt"])
    .agg(pl.col("so_nw_ct").mean().alias("monthly_avg"))
    .sort(["key", "period_dt"])
).to_pandas()

per_key_monthly["period_dt"] = pd.to_datetime(per_key_monthly["period_dt"])

plt.figure(figsize=(20,8))
sns.lineplot(data=per_key_monthly, x="period_dt", y="monthly_avg", hue="key", marker="o")
plt.title("Top-10 Keys (by pct 3m - leb) — Monthly Average Sales (Pareto 80 subset)")
plt.xlabel("Period")
plt.ylabel("Average Sales (so_nw_ct)")
plt.xticks(all_months, rotation=45)
plt.legend(title="key", bbox_to_anchor=(1.05, 1), loc="upper left")
plt.tight_layout()
plt.show()


# CELL C — top-10 keys split into separate subplots

import matplotlib.pyplot as plt
import pandas as pd

# Get top 10 keys (most negative spike)
top10_keys = (
    lebaran_metrics_df
    .sort("pct 3m - leb")  # most negative first
    .head(10)["key"]
    .to_list()
)

# Filter for those keys
df_top_keys = df_pareto.filter(pl.col("key").is_in(top10_keys))

# Compute monthly average per key
per_key_monthly = (
    df_top_keys
    .group_by(["key", "period_dt"])
    .agg(pl.col("so_nw_ct").mean().alias("monthly_avg"))
    .sort(["key", "period_dt"])
).to_pandas()

per_key_monthly["period_dt"] = pd.to_datetime(per_key_monthly["period_dt"])

# Generate full month index
all_months = pd.date_range(
    start=per_key_monthly["period_dt"].min(),
    end=per_key_monthly["period_dt"].max(),
    freq="MS"
)

# Create subplots (one per key)
fig, axes = plt.subplots(len(top10_keys), 1, figsize=(18, 3*len(top10_keys)), sharex=True)

if len(top10_keys) == 1:
    axes = [axes]  # safety if only 1 key

for ax, key in zip(axes, top10_keys):

    key_data = per_key_monthly[per_key_monthly["key"] == key]

    ax.plot(key_data["period_dt"], key_data["monthly_avg"], marker="o")
    ax.set_title(f"Key: {key}")
    ax.set_ylabel("Avg Sales")

    # Lebaran markers
    lebaran_cfg = {2023:4, 2024:4, 2025:3}
    for year, month in lebaran_cfg.items():
        lebaran_date = pd.Timestamp(f"{year}-{month:02d}-01")
        ax.axvline(lebaran_date, linestyle="--", linewidth=1)

    ax.grid(True)

axes[-1].set_xticks(all_months)
axes[-1].set_xticklabels(all_months.strftime("%Y-%m"), rotation=45)

plt.tight_layout()
plt.show()


# === CELL: Plot top-10 keys split by subplot with Lebaran markers and per-key averages ===
import math
import matplotlib.pyplot as plt
import pandas as pd
import polars as pl

# ---------------------
# Configuration
# ---------------------
top_n = 10
ncols = 2
ymax = 5000                     # common upper y-limit
lebaran_cfg = {2023:4, 2024:4, 2025:3}   # Lebaran mapping

# ---------------------
# 1) pick top-N keys by pct 3m - leb (most negative first: biggest spikes)
#    adjust column name if you renamed it earlier
top_keys = lebaran_metrics_df.sort("pct 3m - leb").head(top_n)["key"].to_list()

# safety if < top_n available
top_keys = list(dict.fromkeys(top_keys))  # preserve order, dedupe
if len(top_keys) == 0:
    raise ValueError("No top keys found — make sure lebaran_metrics_df exists and has 'pct 3m - leb' & 'key' columns.")

# ---------------------
# 2) prepare per-key monthly averages (from df_pareto)
# ---------------------
# Ensure df_pareto has period_dt as date: if not, create it
if "period_dt" not in df_pareto.columns:
    df_pareto = df_pareto.with_columns(pl.col("periods").str.strptime(pl.Date, "%Y %m").alias("period_dt"))

# filter only top keys
df_top_keys = df_pareto.filter(pl.col("key").is_in(top_keys))

# group to get monthly average per key
per_key_monthly_pl = (
    df_top_keys
    .group_by(["key", "period_dt"])
    .agg(pl.col("so_nw_ct").mean().alias("monthly_avg"))
    .sort(["key", "period_dt"])
)

per_key_monthly_pd = per_key_monthly_pl.to_pandas()
per_key_monthly_pd["period_dt"] = pd.to_datetime(per_key_monthly_pd["period_dt"])

# pivot to have index=period_dt, columns=key for easier plotting / reindexing
pivoted = per_key_monthly_pd.pivot(index="period_dt", columns="key", values="monthly_avg")

# full month index (month-starts)
all_months = pd.date_range(start=pivoted.index.min(), end=pivoted.index.max(), freq="MS")

# reindex pivoted to include all months (missing are NaN)
pivoted = pivoted.reindex(all_months).sort_index()

# ---------------------
# 3) compute per-key average m3/m2/m1/lebaran from lebaran_metrics_df
#    (we show these averages for each plotted key)
# ---------------------
avg_table = (
    lebaran_metrics_df
    .filter(pl.col("key").is_in(top_keys))
    .group_by("key")
    .agg([
        pl.col("m3_sales").mean().alias("avg_m3"),
        pl.col("m2_sales").mean().alias("avg_m2"),
        pl.col("m1_sales").mean().alias("avg_m1"),
        pl.col("lebaran_sales").mean().alias("avg_lebaran")
    ])
).to_pandas().set_index("key")

# ---------------------
# 4) plotting: grid subplots (2 cols x ceil(N/2) rows)
# ---------------------
nplots = len(top_keys)
nrows = math.ceil(nplots / ncols)
fig, axes = plt.subplots(nrows, ncols, figsize=(16, 4 * nrows), sharex=True, sharey=False)
axes = axes.flatten() if nplots > 1 else [axes]

for i, key in enumerate(top_keys):
    ax = axes[i]

    # series for this key (may contain NaNs)
    series = pivoted[key] if key in pivoted.columns else pd.Series(index=all_months, dtype=float)
    # plot series
    ax.plot(all_months, series.values, marker="o", linewidth=1.25)
    ax.set_title(f"Key: {key}", fontsize=11)
    ax.set_ylabel("Avg Sales")

    # set same y-limit for all plots (None lower bound, ymax upper bound)
    ax.set_ylim(bottom=None, top=ymax)

    # show month ticks & labels on every subplot
    ax.set_xticks(all_months)
    ax.set_xticklabels([d.strftime("%Y-%m") for d in all_months], rotation=45, ha="right", fontsize=8)

    # draw Lebaran vertical lines for each year on every subplot
    for year, month in lebaran_cfg.items():
        lebaran_date = pd.Timestamp(f"{year}-{month:02d}-01")
        ax.axvline(lebaran_date, color="orange", linestyle="--", linewidth=1)
        # slightly above top for label placement in axis fraction coordinates
        ax.text(lebaran_date, ymax * 0.98, f"Leb {year}", rotation=90, va="top", ha="center", fontsize=8, color="orange")

    # annotate the averages (m3/m2/m1/leb) inside the subplot at top-left
    if key in avg_table.index:
        a = avg_table.loc[key]
        text = (f"avg m3: {a['avg_m3']:.2f}\n"
                f"avg m2: {a['avg_m2']:.2f}\n"
                f"avg m1: {a['avg_m1']:.2f}\n"
                f"avg leb: {a['avg_lebaran']:.2f}")
    else:
        text = "no avg data"
    ax.text(0.02, 0.95, text, transform=ax.transAxes, fontsize=9, va="top", ha="left",
            bbox=dict(boxstyle="round,pad=0.3", facecolor="white", alpha=0.8))

    ax.grid(True)

# hide any unused subplots
for j in range(nplots, len(axes)):
    fig.delaxes(axes[j])

plt.suptitle(f"Top {len(top_keys)} Keys by pct 3m - leb (Pareto subset)", fontsize=14)
plt.tight_layout(rect=[0, 0, 1, 0.96])
plt.show()

-----------------------------------------------------------------------



-----------------------------------------------------------------------



-----------------------------------------------------------------------
